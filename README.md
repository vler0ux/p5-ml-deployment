---
title: P5 ML Deployment
emoji: ü§ñ
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
---


# P5 - D√©ploiement ML - Attrition RH

API de pr√©diction d'attrition des employ√©s d√©velopp√©e avec FastAPI.

## üåê D√©ploiement en ligne

L'API est d√©ploy√©e sur Hugging Face Spaces :  
**URL** : https://vler0ux-p5-ml-deployment.hf.space

- Documentation Swagger : https://vler0ux-p5-ml-deployment.hf.space/docs
- Sur le plan gratuit, le Space s'endort apr√®s 48h d'inactivit√© et se r√©veille automatiquement au premier acc√®s (30-60 secondes).


# API Attrition RH ‚Äî Projet P5

D√©ploiement d'un mod√®le de Machine Learning pour pr√©dire le risque de d√©part des employ√©s chez Futurisys.

##  Description

Ce projet expose un mod√®le de **R√©gression Logistique** via une API REST FastAPI. Chaque pr√©diction est enregistr√©e dans une base PostgreSQL pour assurer une tra√ßabilit√© compl√®te des interactions.

**Mod√®le** : Logistic Regression (scikit-learn) avec StandardScaler  
**Objectif** : Pr√©dire si un employ√© va quitter l'entreprise (classification binaire)  
**Dataset** : 1470 employ√©s, 37 features


## Architecture

```
p5/
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ main.py              # API FastAPI
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ create_db.py         # Cr√©ation des tables
‚îÇ   ‚îú‚îÄ‚îÄ insert_data.py       # Insertion du dataset
‚îÇ   ‚îî‚îÄ‚îÄ db.py                # Connexion SQLAlchemy
‚îú‚îÄ‚îÄ models/                  # Fichiers .joblib (non versionn√©s)
‚îú‚îÄ‚îÄ notebooks/               # Notebook d'entra√Ænement
‚îú‚îÄ‚îÄ tests/                   # Tests unitaires pytest
‚îú‚îÄ‚îÄ .env.example             # Template des variables d'environnement
‚îî‚îÄ‚îÄ .github/workflows/       # CI/CD GitHub Actions
```

##  Installation

### Pr√©requis
- Python 3.11+
- PostgreSQL 16+
- uv (gestionnaire de paquets)


### √âtapes
```bash
# 1. Cloner le repo
git clone https://github.com/TON_USERNAME/p5-ml-deployment.git
cd p5-ml-deployment

# 2. Installer les d√©pendances
uv install

# 3. Configurer les variables d'environnement
cp .env.example .env
# √âditer .env avec vos valeurs

# 4. Configurer PostgreSQL
sudo -u postgres psql
```
```sql
CREATE DATABASE attrition_db;
CREATE USER attrition_user WITH PASSWORD 'votre_mot_de_passe';
GRANT ALL PRIVILEGES ON DATABASE attrition_db TO attrition_user;
GRANT ALL ON SCHEMA public TO attrition_user;
\q
```

```bash
# 5. Cr√©er les tables
uv run python database/create_db.py

# 6. Ins√©rer le dataset
uv run python database/insert_data.py

# 7. G√©n√©rer le mod√®le (ex√©cuter le notebook)
uv run jupyter lab notebooks/02_modelisation.ipynb
```

## Lancement

```bash
uv run uvicorn api.main:app --reload
```

- API : `http://localhost:8000`
- Documentation Swagger : `http://localhost:8000/docs`

## üì°Endpoints

| M√©thode | Endpoint | Auth | Description |
|---------|----------|------|-------------|
| GET | `/` | ‚ùå | Message de bienvenue |
| GET | `/health` | ‚ùå | Statut de l'API |
| POST | `/predict` | ‚úÖ | Pr√©diction de d√©part |

##  Authentification

L'endpoint `/predict` est prot√©g√© par une **API Key**.

Ajoute le header suivant √† chaque requ√™te :
```
X-API-Key: votre_cle_api
```

Dans Swagger, clique sur le cadenas üîí en haut √† droite et entre ta cl√©.

## S√©curit√©

- Les secrets (API Key, mot de passe BDD) sont stock√©s dans `.env` (jamais versionn√©)
- `.env.example` documente les variables n√©cessaires sans exposer les valeurs
- Les fichiers `.joblib` ne sont pas versionn√©s (trop lourds et r√©g√©n√©rables)
- L'acc√®s √† la BDD est limit√© √† un utilisateur d√©di√© avec droits restreints

## Exemple d'utilisation

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: votre_cle_api" \
  -d '{
    "age": 28,
    "revenu_mensuel": 3000,
    "heure_supplementaires": "Oui",
    "satisfaction_employee_environnement": 1,
    "frequence_deplacement": "Frequent"
  }'
```

R√©ponse :
```json
{
  "prediction": 1,
  "label": "Risque de d√©part",
  "probabilite_depart": 0.74
}
```

##  Base de donn√©es

### Structure des tables

**Table `employes`** : dataset complet (1470 lignes)
| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER | Cl√© primaire |
| age | INTEGER | √Çge de l'employ√© |
| revenu_mensuel | FLOAT | Salaire mensuel |
| departement | VARCHAR | D√©partement |
| a_quitte_l_entreprise | VARCHAR | Valeur r√©elle (Oui/Non) |

**Table `predictions`** : historique des pr√©dictions
| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER | Cl√© primaire |
| date_prediction | DATETIME | Horodatage |
| age | INTEGER | √Çge soumis |
| prediction | INTEGER | 0=stable, 1=d√©part |
| probabilite_depart | FLOAT | Score de probabilit√© |

### Processus de stockage
Chaque appel √† `/predict` enregistre automatiquement les inputs et outputs dans la table `predictions` via SQLAlchemy, assurant une tra√ßabilit√© compl√®te.

## Tests

```bash
uv run pytest tests/ -v --cov=api --cov-report=html
```

Le rapport de couverture est g√©n√©r√© dans `htmlcov/`.

## CI/CD

Le pipeline GitHub Actions (`.github/workflows/ci.yml`) :
- S'ex√©cute √† chaque push
- Lance les tests automatiquement
- G√®re les environnements dev et prod via les secrets GitHub

## Stack technique

| Outil | Usage |
|-------|-------|
| FastAPI | API REST |
| Pydantic | Validation des donn√©es |
| scikit-learn | Mod√®le ML |
| PostgreSQL | Base de donn√©es |
| SQLAlchemy | ORM |
| uv | Gestionnaire de paquets |
| pytest | Tests unitaires |
| GitHub Actions | CI/CD |

