# p5-ml-deployment
cat > ~/Documents/OpenClassRoom/p5/README.md << 'EOF'
---
title: P5 ML Deployment
emoji: ðŸ¤–
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
---

# P5 - DÃ©ploiement ML - Attrition RH

API de prÃ©diction d'attrition des employÃ©s dÃ©veloppÃ©e avec FastAPI.
EOF

# API Attrition RH â€” Projet P5

DÃ©ploiement d'un modÃ¨le de Machine Learning pour prÃ©dire le risque de dÃ©part des employÃ©s chez Futurisys.

##  Description

Ce projet expose un modÃ¨le de **RÃ©gression Logistique** via une API REST FastAPI. Chaque prÃ©diction est enregistrÃ©e dans une base PostgreSQL pour assurer une traÃ§abilitÃ© complÃ¨te des interactions.

**ModÃ¨le** : Logistic Regression (scikit-learn) avec StandardScaler  
**Objectif** : PrÃ©dire si un employÃ© va quitter l'entreprise (classification binaire)  
**Dataset** : 1470 employÃ©s, 37 features

## Architecture

```
p5/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py              # API FastAPI
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ create_db.py         # CrÃ©ation des tables
â”‚   â”œâ”€â”€ insert_data.py       # Insertion du dataset
â”‚   â””â”€â”€ db.py                # Connexion SQLAlchemy
â”œâ”€â”€ models/                  # Fichiers .joblib (non versionnÃ©s)
â”œâ”€â”€ notebooks/               # Notebook d'entraÃ®nement
â”œâ”€â”€ tests/                   # Tests unitaires pytest
â”œâ”€â”€ .env.example             # Template des variables d'environnement
â””â”€â”€ .github/workflows/       # CI/CD GitHub Actions
```

##  Installation

### PrÃ©requis
- Python 3.11+
- PostgreSQL 16+
- uv (gestionnaire de paquets)


### Ã‰tapes
```bash
# 1. Cloner le repo
git clone https://github.com/TON_USERNAME/p5-ml-deployment.git
cd p5-ml-deployment

# 2. Installer les dÃ©pendances
uv install

# 3. Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env avec vos valeurs

# 4. Configurer PostgreSQL
sudo -u postgres psql
```
```sql
CREATE DATABASE attrition_db;
CREATE USER attrition_user WITH PASSWORD 'votre_mot_de_passe';
GRANT ALL PRIVILEGES ON DATABASE attrition_db TO attrition_user;
GRANT ALL ON SCHEMA public TO attrition_user;
\q
```

```bash
# 5. CrÃ©er les tables
uv run python database/create_db.py

# 6. InsÃ©rer le dataset
uv run python database/insert_data.py

# 7. GÃ©nÃ©rer le modÃ¨le (exÃ©cuter le notebook)
uv run jupyter lab notebooks/02_modelisation.ipynb
```

## Lancement

```bash
uv run uvicorn api.main:app --reload
```

- API : `http://localhost:8000`
- Documentation Swagger : `http://localhost:8000/docs`

## ðŸ“¡Endpoints

| MÃ©thode | Endpoint | Auth | Description |
|---------|----------|------|-------------|
| GET | `/` | âŒ | Message de bienvenue |
| GET | `/health` | âŒ | Statut de l'API |
| POST | `/predict` | âœ… | PrÃ©diction de dÃ©part |

##  Authentification

L'endpoint `/predict` est protÃ©gÃ© par une **API Key**.

Ajoute le header suivant Ã  chaque requÃªte :
```
X-API-Key: votre_cle_api
```

Dans Swagger, clique sur le cadenas ðŸ”’ en haut Ã  droite et entre ta clÃ©.

## SÃ©curitÃ©

- Les secrets (API Key, mot de passe BDD) sont stockÃ©s dans `.env` (jamais versionnÃ©)
- `.env.example` documente les variables nÃ©cessaires sans exposer les valeurs
- Les fichiers `.joblib` ne sont pas versionnÃ©s (trop lourds et rÃ©gÃ©nÃ©rables)
- L'accÃ¨s Ã  la BDD est limitÃ© Ã  un utilisateur dÃ©diÃ© avec droits restreints

## Exemple d'utilisation

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: votre_cle_api" \
  -d '{
    "age": 28,
    "revenu_mensuel": 3000,
    "heure_supplementaires": "Oui",
    "satisfaction_employee_environnement": 1,
    "frequence_deplacement": "Frequent"
  }'
```

RÃ©ponse :
```json
{
  "prediction": 1,
  "label": "Risque de dÃ©part",
  "probabilite_depart": 0.74
}
```

##  Base de donnÃ©es

### Structure des tables

**Table `employes`** : dataset complet (1470 lignes)
| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER | ClÃ© primaire |
| age | INTEGER | Ã‚ge de l'employÃ© |
| revenu_mensuel | FLOAT | Salaire mensuel |
| departement | VARCHAR | DÃ©partement |
| a_quitte_l_entreprise | VARCHAR | Valeur rÃ©elle (Oui/Non) |

**Table `predictions`** : historique des prÃ©dictions
| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER | ClÃ© primaire |
| date_prediction | DATETIME | Horodatage |
| age | INTEGER | Ã‚ge soumis |
| prediction | INTEGER | 0=stable, 1=dÃ©part |
| probabilite_depart | FLOAT | Score de probabilitÃ© |

### Processus de stockage
Chaque appel Ã  `/predict` enregistre automatiquement les inputs et outputs dans la table `predictions` via SQLAlchemy, assurant une traÃ§abilitÃ© complÃ¨te.

## Tests

```bash
uv run pytest tests/ -v --cov=api --cov-report=html
```

Le rapport de couverture est gÃ©nÃ©rÃ© dans `htmlcov/`.

## CI/CD

Le pipeline GitHub Actions (`.github/workflows/ci.yml`) :
- S'exÃ©cute Ã  chaque push
- Lance les tests automatiquement
- GÃ¨re les environnements dev et prod via les secrets GitHub

## Stack technique

| Outil | Usage |
|-------|-------|
| FastAPI | API REST |
| Pydantic | Validation des donnÃ©es |
| scikit-learn | ModÃ¨le ML |
| PostgreSQL | Base de donnÃ©es |
| SQLAlchemy | ORM |
| uv | Gestionnaire de paquets |
| pytest | Tests unitaires |
| GitHub Actions | CI/CD |